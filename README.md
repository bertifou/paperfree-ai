# PaperFree-AI ğŸ“„ğŸš€

Une solution open-source pour la gestion intelligente de documents, inspirÃ©e par Immich.
Tout tourne en local : OCR, LLM, stockage.

## ğŸŒŸ Vision
- **ConfidentialitÃ© Totale** : Aucune donnÃ©e n'quitte votre rÃ©seau.
- **Capture Mobile** : Scan depuis le navigateur ou l'app compagnon.
- **IA Flexible** : Compatible LM Studio, Ollama, OpenAI ou tout backend OpenAI-compatible.
- **AccÃ¨s Universel** : RÃ©seau local + accÃ¨s distant sÃ©curisÃ©.

## ğŸ—ï¸ Stack
- **Backend** : FastAPI (Python 3.11)
- **OCR** : Tesseract (local)
- **LLM** : OpenAI-compatible (LM Studio / Ollama / OpenAI)
- **DB** : SQLite
- **Frontend** : HTML/JS vanilla (Tailwind CSS)
- **DÃ©ploiement** : Docker Compose

## ğŸš€ DÃ©marrage rapide

```bash
# 1. Cloner le repo
git clone https://github.com/bertifou/paperfree-ai.git
cd paperfree-ai

# 2. Configurer l'environnement
cp .env.example .env
# Ã‰diter .env : renseigner LLM_BASE_URL selon votre backend

# 3. Lancer avec Docker
docker-compose up -d

# 4. Ouvrir le frontend
# http://localhost:8080
# (PremiÃ¨re visite â†’ Ã©cran de configuration du compte admin)
```

## âš™ï¸ Configuration LLM

Modifier `LLM_BASE_URL` dans `.env` :

| Backend    | URL                              |
|------------|----------------------------------|
| LM Studio  | `http://localhost:1234/v1`       |
| Ollama     | `http://localhost:11434/v1`      |
| OpenAI     | `https://api.openai.com/v1`      |

La config peut aussi Ãªtre modifiÃ©e Ã  chaud depuis l'interface web (onglet ParamÃ¨tres).

## ğŸ“ Structure

```
paperfree-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py          # API FastAPI
â”‚   â”œâ”€â”€ processor.py     # OCR + analyse LLM
â”‚   â”œâ”€â”€ database.py      # ModÃ¨les SQLAlchemy
â”‚   â”œâ”€â”€ email_monitor.py # Surveillance boÃ®te mail
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ .env.example
```

## ğŸ› ï¸ FonctionnalitÃ©s

- [x] Upload de documents (PDF, images)
- [x] OCR local (Tesseract, francais + anglais)
- [x] **Score de confiance OCR** â€” Tesseract retourne un score par mot (0â€“100 %)
- [x] **Correction OCR par LLM** â€” le texte brut est envoyÃ© au LLM pour corriger l/1/I, 0/O, mots coupÃ©sâ€¦ Le score de confiance sert de signal d'incertitude
- [x] **Analyse par vision (LLM multimodal)** â€” bypass OCR, envoie l'image directement au LLM. Compatible LM Studio (llava, minicpm-vâ€¦), OpenAI (gpt-4o) ou Anthropic (claude-3-5-sonnet). Configurable par provider dans les ParamÃ¨tres
- [x] Classification automatique par LLM (Facture, ImpÃ´ts, SantÃ©â€¦)
- [x] Extraction structurÃ©e (date, montant, Ã©metteur)
- [x] Recherche plein texte
- [x] Suppression de documents
- [x] Surveillance de dossier (watchdog)
- [x] Configuration LLM modifiable Ã  chaud
- [x] CORS configurÃ©
- [ ] Surveillance boÃ®te mail (email_monitor.py â€” branchÃ© prochainement)
- [ ] Application mobile compagnon
- [ ] Authentification JWT
- [ ] Pagination

## ğŸ” Pipeline OCR & Vision

```
Image uploadÃ©e
     â”‚
     â”œâ”€â”€â”€ Vision activÃ©e ? â”€â”€YESâ”€â”€â†’ Image en base64 â†’ LLM multimodal â†’ JSON structurÃ©
     â”‚                                                                        â”‚
     â”‚                                                                  Texte extrait (stored)
     â”‚
     â””â”€â”€â”€ Vision dÃ©sactivÃ©e â”€â”€â†’ Tesseract OCR
                                     â”‚
                               Score confiance (0â€“100%)
                                     â”‚
                               Correction LLM si < seuil
                               (ou systÃ©matique si activÃ©e)
                                     â”‚
                               Texte corrigÃ© â†’ LLM â†’ JSON structurÃ©
```

| Mode | Avantages | InconvÃ©nients |
|------|-----------|---------------|
| OCR seul | Rapide, 100% local | Erreurs sur docs complexes |
| OCR + correction LLM | Meilleure qualitÃ©, 100% local | RequÃªte LLM supplÃ©mentaire |
| Vision locale (llavaâ€¦) | Excellent sur manuscrits/tampons, local | ModÃ¨le vision requis, plus lent |
| Vision OpenAI/Anthropic | QualitÃ© maximale | DonnÃ©es envoyÃ©es dans le cloud |

