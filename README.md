# PaperFree-AI ğŸ“„ğŸš€

Une solution open-source pour la gestion intelligente de documents, inspirÃ©e par Immich.
Tout tourne en local : OCR, LLM, stockage.

## ğŸŒŸ Vision
- **ConfidentialitÃ© Totale** : Aucune donnÃ©e n'quitte votre rÃ©seau.
- **Capture Mobile** : Scan depuis le navigateur ou l'app compagnon.
- **IA Flexible** : Compatible LM Studio, Ollama, OpenAI ou tout backend OpenAI-compatible.
- **AccÃ¨s Universel** : RÃ©seau local + accÃ¨s distant sÃ©curisÃ©.
- **ğŸ”’ SÃ©curitÃ© RenforcÃ©e** : JWT, rate limiting, validation stricte des uploads.

## ğŸ—ï¸ Stack
- **Backend** : FastAPI (Python 3.11)
- **OCR** : Tesseract (local)
- **LLM** : OpenAI-compatible (LM Studio / Ollama / OpenAI)
- **DB** : SQLite
- **Frontend** : HTML/JS vanilla (Tailwind CSS)
- **DÃ©ploiement** : Docker Compose
- **SÃ©curitÃ©** : JWT, rate limiting, validation MIME, headers sÃ©curisÃ©s

## ğŸš€ DÃ©marrage rapide

```bash
# 1. Cloner le repo
git clone https://github.com/bertifou/paperfree-ai.git
cd paperfree-ai

# 2. Configurer l'environnement
cp .env.example .env
# Ã‰diter .env : renseigner LLM_BASE_URL selon votre backend

# 3. Lancer avec Docker
docker-compose up -d

# 4. Ouvrir le frontend
# http://localhost:8080
# (PremiÃ¨re visite â†’ Ã©cran de configuration du compte admin)
```

## âš™ï¸ Configuration LLM

Modifier `LLM_BASE_URL` dans `.env`, ou choisir directement depuis l'interface web (onglet ParamÃ¨tres â†’ boutons de sÃ©lection rapide) :

| Backend        | URL                                                                 | ModÃ¨les suggÃ©rÃ©s                                    |
|----------------|---------------------------------------------------------------------|-----------------------------------------------------|
| LM Studio      | `http://localhost:1234/v1`                                          | `local-model`                                       |
| Ollama         | `http://localhost:11434/v1`                                         | `llama3`, `mistral`, `qwen2.5`                      |
| OpenAI         | `https://api.openai.com/v1`                                         | `gpt-4o-mini`, `gpt-4o`                             |
| Google Gemini  | `https://generativelanguage.googleapis.com/v1beta/openai/`         | `gemini-2.5-flash-preview-05-20`, `gemini-2.0-flash`, `gemini-1.5-flash` |

> **Gemini** : ClÃ© API gratuite disponible sur [aistudio.google.com/apikey](https://aistudio.google.com/apikey).  
> L'API Gemini expose un endpoint compatible OpenAI â€” aucune librairie supplÃ©mentaire requise.

La config peut aussi Ãªtre modifiÃ©e Ã  chaud depuis l'interface web (onglet ParamÃ¨tres).

## ğŸ“ Structure

```
paperfree-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py          # API FastAPI
â”‚   â”œâ”€â”€ processor.py     # OCR + analyse LLM
â”‚   â”œâ”€â”€ database.py      # ModÃ¨les SQLAlchemy
â”‚   â”œâ”€â”€ email_monitor.py # Surveillance boÃ®te mail
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ .env.example
```

## ğŸ› ï¸ FonctionnalitÃ©s

- [x] Upload de documents (PDF, images)
- [x] OCR local (Tesseract, franÃ§ais + anglais)
- [x] **Score de confiance OCR** â€” Tesseract retourne un score par mot (0â€“100 %)
- [x] **Correction OCR par LLM** â€” le texte brut est envoyÃ© au LLM pour corriger l/1/I, 0/O, mots coupÃ©sâ€¦
- [x] **Analyse par vision (LLM multimodal)** â€” bypass OCR, envoie l'image directement au LLM
- [x] Classification automatique par LLM (Facture, ImpÃ´ts, SantÃ©â€¦)
- [x] Extraction structurÃ©e (date, montant, Ã©metteur)
- [x] Recherche plein texte
- [x] Suppression de documents
- [x] Surveillance de dossier (watchdog)
- [x] Configuration LLM modifiable Ã  chaud
- [x] **Authentification JWT** â€” tokens sÃ©curisÃ©s pour API et mobile
- [x] **Rate limiting** â€” protection contre brute force et abus
- [x] **Validation stricte des uploads** â€” vÃ©rification MIME, taille, extensions
- [x] **Headers de sÃ©curitÃ© HTTP** â€” HSTS, CSP, XSS protection
- [x] **Logging de sÃ©curitÃ©** â€” traÃ§age des Ã©vÃ©nements critiques
- [ ] Surveillance boÃ®te mail (email_monitor.py â€” branchÃ© prochainement)
- [ ] Application mobile compagnon
- [ ] Authentification multi-facteur (2FA)
- [ ] Pagination

## ğŸ” Pipeline OCR & Vision

```
Image uploadÃ©e
     â”‚
     â”œâ”€â”€â”€ Vision activÃ©e ? â”€â”€YESâ”€â”€â†’ Image en base64 â†’ LLM multimodal â†’ JSON structurÃ©
     â”‚                                                                        â”‚
     â”‚                                                                  Texte extrait (stored)
     â”‚
     â””â”€â”€â”€ Vision dÃ©sactivÃ©e â”€â”€â†’ Tesseract OCR
                                     â”‚
                               Score confiance (0â€“100%)
                                     â”‚
                               Correction LLM si < seuil
                               (ou systÃ©matique si activÃ©e)
                                     â”‚
                               Texte corrigÃ© â†’ LLM â†’ JSON structurÃ©
```

| Mode | Avantages | InconvÃ©nients |
|------|-----------|---------------|
| OCR seul | Rapide, 100% local | Erreurs sur docs complexes |
| OCR + correction LLM | Meilleure qualitÃ©, 100% local | RequÃªte LLM supplÃ©mentaire |
| Vision locale (llavaâ€¦) | Excellent sur manuscrits/tampons, local | ModÃ¨le vision requis, plus lent |
| Vision OpenAI/Anthropic | QualitÃ© maximale | DonnÃ©es envoyÃ©es dans le cloud |

